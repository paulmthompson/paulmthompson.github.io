
#+TITLE: Kalman Filter

* Definition
* Overview

A *Kalman Filter* represents the optimal way to combine an incoming
noisy *measurement* about the state of a system with a *prediction*
about the current state of the system based on the *prior* system
state as well as the model of how the system progressing. 

The measurement and prediction are going to have some associated error
with them. The optimal way to combine these quantities can be done by
considering the *variance* associated with each value, and weighing
the value with the lowest variance more strongly than the other.

The statistical assumptions for this to take place are therefore that
the noise is *normally distributed (gaussian)* as well as *zero mean
(white)*. Because the system will be progressing forward, we must
therefore assume that it is a *linear system*, so that it continues to
stay gaussian and white.

In real life, unfortunately, most of those assumptions do not
hold. There are some tricks, however, to try to apply the techniques
of the kalman filter to nonlinear systems.

One way to deal with a nonlinear system is to *linearize* the
system. This is the concept behind the *extended kalman filter*. This can be computationally intense, and causes the linearized
function to be computed everytime. The error here is coming from
representing the system with a different equation.

Another possibility is to hand pick data points from the system that
represent the data, but make it look normally distributed. This is the
theory behind the *unscented kalman filter*. Now, the system can
actually be evaulated with its true nonlinear equation, because each
point in time a new, normal distribution of points will be selected,
so it doesn't matter if the nonlinear equations change the
distribution of the data. So the error comes from picking points to
represent the system as a normally distributed system rather than how
it really is.

* Kalman Filter Basics
** Assumptions

*** Linear System

*** White Noise

*** Gaussian Noise

** Simple 1D Theory

The Kalman filter involves combining estimates of the same value but
with different variance. The optimal to combine these values would be
to average them weighted by the variance of the measurement. 

\begin{align}
\hat{x}_{t_2} &= [\sigma_{z_2}^2/(\sigma_{z_2}^2 + \sigma_{z_1}^2)^2]z_1 +
[\sigma_{z_1}^2/(\sigma_{z_2}^2 + \sigma_{z_1}^2)^2]z_2 \\
&= z_1 + [\sigma_{z_1}^2/(\sigma_{z_2}^2 + \sigma_{z_1}^2)^2][z_2-z_1]
\end{align}

The new variance would likewise a combination of the two as well
\begin{equation}
1/\sigma^2 = 1/\sigma_{z_1}^2)^2 + 1/\sigma_{z_2}^2
\end{equation}

Kalman filter notation uses the form.

\begin{equation}
\hat{x}(t_2) = \hat{x}(t_1) + K(t_2)[z_2 - \hat{x}(t_1)]
\end{equation}

where K(t_2) is equal to

\begin{equation}
K(t_2) = \sigma_{z_1}^2/(\sigma_{z_2}^2 + \sigma_{z_1}^2)^2
\end{equation}

As time progresses, the state is updated by the prediction of the
future state based on the system as well as measurements of the
system (which have some uncertainty). 

Later in time, before the next
measurement is made, the state predicted based on the past state (with
its prior uncertainty) along with how you believe that the system has
progressed (with its associated uncertainty)

\begin{equation}
\hat{x}(t^-_3) = \hat{x}_{t_2} + g(x,t)(t_3-t_2)
\end{equation}
\begin{equation}
\sigma_{x}^2(t^-_3) = \sigma_{x}^2(t_2) + \sigma_{g(x,t)}^2(t_3-t_2)
\end{equation}

So increasing time makes the estimate more uncertain.

This can then be combined with the incoming measurement in a similar
way as previously

\begin{equation}
\hat{x}(t_3) = \hat{x}(t^-_3)  + K(t_3)[z_3 - \hat{x}(t^-_3)]
\end{equation}
\begin{equation}
\sigma_{x}^2(t_3) = \sigma_{x}^2(t^-_3) - K(t_3) \sigma_{x}^2(t^-_3)
\end{equation}
\begin{equation}
K(t_3) = \sigma_{x}^2(t^-_3)/[\sigma_{x}^2(t^-_3) + \sigma_{z_3}^2]
\end{equation}



** Terms and Equations
First we have a system we are trying to model. We are assuming that
this system is linear and stochastic, so all of its possible
components are

\begin{equation}
x_k = Ax_{k-1} + Bu_{k-1} + w_{k-1}
\end{equation}

x_k represents the system at some step k. A is a n x n matrix
that relates the past (x_{k-1}) to the present. The other term, B, may or
may not be present, and it is a m x n matrix that relates a possible *control input*
u_{k-1} to the current state of the system. w_k is the noise inherent
in the process.

We are going to be measuring this system. Our measurement will not be
a perfect representation, and will be related to the system as the
following

\begin{equation}
z_k = Hx_k + v_k
\end{equation}

So our measurement z_k is related to the true value of the state x_k,
by the matrix H (you might not always be measuring the state directly,
like resistance and current), along with some measurement noise, v_k.

Both of the noise terms, becuase this is a Kalman filter, are assumed
to be white and Gaussian and therefore have the following probability
distributions with respective covariances Q and R.

\begin{align}
p(w) ~ N(0,Q) \\
p(v) ~ N(0,R)
\end{align}

Now we are going to be estimating states in the kalman filter, so we
will desinate our estimates with a hate to distinguish them from the
true value of the state 
\begin{equation} 
\hat{x}_k 
\end{equation}

With the Kalman filter we are going to be trying to optimally
"combine" our estimate of the state based on how we believe the system
to function (our linear stochastic difference equation), with updated
measurements. To do this, we are going to combine our most up-to-date
prediction with the measurement. That is, we will combine our
prediction at step k immediately before we take the measurement with
the new measurement. This estimate immediately before our measurement
at step k will be designated

\begin{equation}
\hat{x}^-_k
\end{equation}

The value of this term is our expected value of the system at time
step k. To our best knowable, it will evolve according to our estimate
of the state.

\begin{equation}
\hat{x}^-_k = A \hat{x}_{k-1}
\end{equation}

In Bayesian terms, we can speak of our state before the measurement as
our *prior* and our state after the measurement given the measurement
as the *posterior*. We can calculate the error before the measurement
and after the measurement (note both of these are still at the same
time step k)

\begin{align}
e_k^- = x_k - \hat{x}_k^- \\
e_k = x_k - \hat{x}_k
\end{align}

The prior and posterior estimate error covariances can be represented
with the standard definition of covariance and then substituing in our
definition of error above

\begin{align}
P^-_k = E[(x_k - \hat{x}^-_k ) (x_k - \hat{x}^-_k)^T] = E[e^-_k (e^-_k)^T] \\
P_k = E[(x_k - \hat{x}_k) (x_k - \hat{x}_k)^T] =E[e_k e^T_k]
\end{align}

So what we finally want is the optimal way to combine the measurement
z_k with the estimate of the state up until that point. We can
represent that as

\begin{equation}
\hat{x}_k = \hat{x}^-_k + K (z_k - H \hat{x}^-_k)
\end{equation}

Because H from above relates the state of the system to the
measurement we get, H will relate the prior state estimate to
*predicted measurement*. So will will use some *gain* or *blending
factor* represented by the n x m matrix K to combine the difference
between the measurement and predicted measurement.

K is determined to be the value that minimizes the posterior error
covariance, which we defined above. So with substitutions,
expectations and derivatives we get a result that depends on H and the
variances of our estimate and measurement. So the greater the variance
of our estimate, the less it will be weighted and vice versa.

** Algorithm

So for each unit k, we need to update our state estimate and then
incorporate the feedback. Our *state prediction* (also known as our
*prior estimate*) is generated from our
stochastic linear model and therefore is equal to

\begin{equation}
\hat{x}^-_k = A \hat{x}_{k-1} + B u_{k-1}
\end{equation}

Our gain term, K, incorporates the variances of the *prior* as
well as the measurement. Therefore we also have to update the of the
prior, which was previously equal to the variance of the posterior on
the last time step, with some increase due to time. We previously
defined the *prior estimate covariance* and *posterior estimate covariance* 

\begin{align}
P^-_k = E[(x_k - \hat{x}^-_k ) (x_k - \hat{x}^-_k)^T] = E[e^-_k (e^-_k)^T] \\
P_k = E[(x_k - \hat{x}_k) (x_k - \hat{x}_k)^T] =E[e_k e^T_k]
\end{align}

We see that our prior estimate covariance involves both the true value
of the system and the prior estimate of the system from the current
step k. We do not have this information available to us. If we
consider how the current state of the system evolves from the linear
stochastic model:

\begin{equation}
x_k = Ax_{k-1} + q_{k-1}
\end{equation}

we can perform some substituion from our *prior* estimate equation
above (assuming B=0) and the linear model equation.

\begin{align}
P^-_k &= E[(x_k - \hat{x}^-_k ) (x_k - \hat{x}^-_k)^T] \\
&= E[((Ax_{k-1} + q_{k-1}) - A \hat{x}_{k-1})(Ax_{k-1} + q_{k-1} - A \hat{x}_{k-1})] \\
\end{align}

A lot of horrifying algebra will result in this equation for the
variance

\begin{equation}
P^-_k = AP_{k-1}A^T+Q
\end{equation}

Updating the measurement is a lot simplier and just involves the
equations we derived earlier.

\begin{align}
K_k = P^-_k H^T (HP^-_k H^T + R)^-1 \\
\hat{x}_k = \hat{x}^-_k + K_k(z_k - H \hat{x}^-_k) \\
P_k = (1 - K_k H)P^-_k
\end{align}

So our steps in order are 1) compute Kalman gain K_k ; 2) measure to
get z_k ; 3) generate the *posterior* from the *prior*; 4) get
*posterior convariance*

** Extended Kalman Filter
*** Concept
Extended Kalman filter is a tool for dealing with a nonlinear process,
nonlinear measurement-state relationship or both.

To apply the Kalman filter to these situations, the equations describe
the system (and measurement if applicable) need to be linearized.

*** Nonlinear System equations
So our system can be represented by a nonlinear stochastic difference equation

\begin{equation}
x_k = f(x_{k-1}, u_{k-1}, w_{k-1}) = f(x_{k-1}, u_{k-1}) + w_{k-1}
\end{equation}

and a nonlinear measurement equation

\begin{equation}
z_k = h(x_k,v_k) = h(x_k) + v_k
\end{equation}
*** Linearization
How are we going to most accurately linearize the system above? In
other words, we want to pick f(?) to best model the system. We
cannot pick our initial condition point, because as we move forward in
the state of the system, the model will become less and less
accurate. f(x_{k-1}) would be a good choice, but we do not have access
to the true value of the state. \hat{x}_{k-1} is information we do
have access to, but we again run into problems because we do not know
w_{k-1} which is the process noise at the last step. Therefore, our
best choice of a point to linearize around is our function evaluated
at \hat{x}_{k-1} without the noise. We will define these points as
follows:

\begin{equation}
\tilde{x}_k = f(\hat{x}_{k-1} , u_{k-1} , 0)
\end{equation}

\begin{equation}
\tilde{z}_k = f(\tilde{x}_k, 0)
\end{equation}

So in summary, we are going to linearize our system about the point
where w_{k-1}=0 and x_{k-1} = \hat{x}_{k-1} becuase this is the best
informatino available to us and will therefore give the best
estimate. We can do this by taking the multivariate Taylor series
expansion and discarding the terms higher than second order:

\begin{align}
f(x,y) &= f(a,b) + f_x(a,b)(x-a) + f_y(a,b)(x-b) \\

x_k = f(x_{k-1},w_{k-1}) &=  f(a,b) + f_{x_{k-1}}(a,b)(x_{k-1}-a) + f_{w_{k-1}}(a,b)(w_{k-1}-b)\\

&= f(\hat{x}_{k-1}, u_{k-1}, 0) + (f_{x_{k-1}}(\hat{x}_{k-1}
, u_{k-1} , 0))(x-\hat{x}_{k-1}) + (f_{w_{k-1}}(\hat{x}_{k-1},
u_{k-1}, 0))(w_{k-1}-0) \\

&= \tilde{x}_k + (f_{x_{k-1}}(\hat{x}_{k-1}
, u_{k-1} , 0))(x-\hat{x}_{k-1}) + (f_{w_{k-1}}(\hat{x}_{k-1},
u_{k-1}, 0))(w_{k-1})

\end{align}

We can follow a similar procedure of linearizing the measurement value
about \tilde{z_k} to find the following

\begin{equation}
z_k = \tilde{z}_k + (h_{x_k}(\tilde{z}_k, 0))(x_k - \tilde{x}_k) + (h_{v_k}(\tilde{z}_k, 0))(v_k)
\end{equation}

All of our equations are linearized around \hat{x}_k, so this is our
best guess or *prediction* of what is to come. 

We can make some of equations easier to look at by defining the
following terms

\begin{align}
A &= (f_{x_{k-1}}(\hat{x}_{k-1}
, u_{k-1} , 0)) \\
W &= (f_{w_{k-1}}(\hat{x}_{k-1},
u_{k-1}, 0)) \\
H &= (h_{x_k}(\tilde{z}_k, 0)) \\
V &= (h_{v_k}(\tilde{z}_k, 0))
\end{align}
*** Determine Covariance
We must also then
determine the *covariance* associated with this. More horrifying
algebra will lead us to the following

\begin{align}
P^-_k &= E[(x_k - \tilde{x}_k)(x_k - \tilde{x}_k)] \\
&= E[(A_k (x_{k-1} - \hat{x}_k{k-1}) + W_k w_{k-1})(A_k (x_{k-1} -
\hat{x}_k{k-1}) + W_k w_{k-1})^T \\
&= ...Algebra... \\
&= A_k P_{k-1} A^T_k + W_k Q_{k-1} W^T_k
\end{align}

*** Equations

In the linear Kalman filter, the predictions were generated by taking
the expectation of the equations governing the system equations. For
the extended Kalman filter, we do not take the expectation of these
nonlinear functions, but instead *estimate* as a function of the prior
mean value. Because the mean value for noise should be zero, noise is
not included in these estimates.

*Time update equations*

\begin{align}
\hat{x}^-_k &= f(\hat{x}_{k-1}, u_{k-1}, 0) \\
P^-_k &= A_k P_{k-1} A^T_k + W_k Q_{k-1} W^T_k
\end{align}

*Measurement update equations*
\begin{align}
K_k &= P^-_k H^T_k (H_k P^-_k H^T_k + V_k R_k V^T_k)^{-1} \\
\hat{x}_k &= \hat{x}^-_k + K_k (z_k - h( \hat{x}^-_k, 0)) \\
P_k &= (1 - K_k H_k) P^-_k
\end{align}

** Unscented Kalman Filter
*** Concept
In essence, the probability distribution is being approximated rather
than approximating the non-linear system.

Choses sample points to represent the true mean and covariance of
Gaussian random variables.. Propogate these values through the true
non linear system.

The chosen point are known as *sigma points* which have corresponding weights.

*** Unscented Transform


* BCI
** Parameters
*** Standard Kalman

z_k is a C length vector that contains firing rates for C neurons.

H relates the firing rates to the state (which could be things like
hand velocity in multiple directions, position, force, EMG, etc)

R is the covariance of the measurement (zero mean and normally
distributed is assumed for Kalman). Because the firing rate data is
not necessarily this way, some groups have transformed it (square
root) to make it better modeled by a normal distribution. Can be used
full or not full?

A is the size of the states estimated

There is probably a time lag between the encoding firing rate and the
state of the system that results (x_k should consider z_{k-i} where i
represents some step lag). Cells can be assumed to have *uniform lag*
or *nonuniform lag*. Nonuniform lag is probably better. \cite{Wu2006a}.

** Learning and Decoding

The matrices A, H R, and Q all have to be learned.

If they are to maximize the join probability p(x,z) the solutions are \cite{Wu2006a}

\begin{align}
A = ( \sum_{k=2}^M (x_k x^T_{k-1})) ( \sum_{k=2}^M (x_{k-1} x^T_{k-1}))^{-1}
\\
W = 1/(M-1) ( \sum_{k=2}^M (x_k x^T_k) - A \sum_{k=2}^M (x_{k-1}
x^T_k)) \\
H = (\sum_{k=1}^M (z_k x_k^T))(\sum_{k=1}^M (x_k x_k^T))^{-1} \\
Q = 1/M (\sum_{k=1}^M (z_k z_k^T) - H \sum_{k=1}^M (x_k z_k^T))
\end{align}

** Experiments

First Wei Wu paper citation is messed up.

\cite{Gao2002}

\cite{Wu2006a} - measuring the error of position (but calculating the
state vector for position, velocity and acceleration) they estimating
several components of the kalman filter. Found that optimal lag was
nonuniform for some tasks, but not by much and the simplicity of using
a uniform time lag was better. Accuracy increased with number of
cells. Found that their model was better than the population vector and
linear filter. Did not compare to neural network.

\cite{Li2009} - unscented Kalman Filter

\cite{Kim2008}

\cite{Kim2011}

\cite{Hochberg2012}

\cite{Gilja2012} - recalibrated feedback intention trained kalman
filter (ReFIT-KF)

* Reviews

\cite{Maybeck1979a} excellent introduction to Kalman filters. I mean
EXCELLENT

http://greg.czerniak.info/guides/kalman1/ - really great summary of
all of the equations and has a couple of examples (1 variable and
multi variable) with code attached.

http://www.cs.unc.edu/~welch/kalman/kalmanIntro.html - contains more
great introductary material building the filter from first principles.

\cite{Bashashati2007}

#+BIBLIOGRAPHY: library plain option:--no-keywords option:--no-abstract limit:t

