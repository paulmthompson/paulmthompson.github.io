
Bayesian Statistics

Bayes' Rule

Odds of event 1 (A_1) and event 2 (A_2) before and after training on another event (B). Expression of event 1 and 2 can be a ratio; therefore the "before" odds ratio is called the *prior* (P(A)) and the "after" odds ratio is called the *posterior* (P(A|B)) which takes into account that training on event B occured. These are related by the *likelihood factor* which is the probability of event B occuring during event 1 or 2 expressed as a ratio as well.



For many events, the posterior odds is proportional to prior odds times likelihood factor.

P(A|B) ~ P(A)P(B|A)

This derives from Baye's Theorem which more generally means that the *conditional probability*, P(A|B) or the degree of belief in A accounting for B, is equal to the *prior probability*, P(A) or initial belief in A, multiplied by the support B provides for A, or P(B|A)/P(B). If P(B) is fixed and A is what is varied, we arrive at P(A|B) ~ P(A)P(B|A).
